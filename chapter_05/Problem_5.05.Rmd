---
title: "Problem 5.5"
author: "Yuwen Tan"
output: html_document
---

### (a) Logistic regression
```{r}
library(ISLR)
glm.fit <- glm(default~income+balance,data = Default,family = binomial)
summary(glm.fit)
```

### (b) Validation set approach
```{r}
set.seed(1)
train <- sample(1:length(Default$default),length(Default$default)/2)
glm.fit <- glm(default~income+balance,data = Default,family = binomial,subset = train)
summary(glm.fit)
glm.probs <- predict(glm.fit,Default[-train,],type = "response")
glm.pred <- rep("No",length(glm.probs))
glm.pred[glm.probs>0.5] <- "Yes"
mean(glm.pred!=Default$default[-train])
```

### (c) Three more splits of the observations
```{r}
for (i in 1:3) {
  train <- sample(1:length(Default$default),length(Default$default)/2)
  glm.fit <- glm(default~income+balance,data = Default,family = binomial,subset = train)
  print(summary(glm.fit))
  glm.probs <- predict(glm.fit,Default[-train,],type = "response")
  glm.pred <- rep("No",length(glm.probs))
  glm.pred[glm.probs>0.5] <- "Yes"
  print(mean(glm.pred!=Default$default[-train]))
}
```

The results are actually very close to each other.

### (d) Validation set approach with the predictor of student
```{r}
set.seed(1)
train <- sample(1:length(Default$default),length(Default$default)/2)
glm.fit <- glm(default~income+balance+student,data = Default,family = binomial,subset = train)
summary(glm.fit)
glm.probs <- predict(glm.fit,Default[-train,],type = "response")
glm.pred <- rep("No",length(glm.probs))
glm.pred[glm.probs>0.5] <- "Yes"
mean(glm.pred!=Default$default[-train])
```

Including a dummy variable of student won't lead to a reduction in the test error rate.